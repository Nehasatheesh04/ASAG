{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1BThtwPvPfYEdC72euG9mcWZHVvD9IVP8",
      "authorship_tag": "ABX9TyNDAzerwG/HvKczWGD/5zcm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "65216fa69c07431c890eb2f34ceff79b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [],
            "layout": "IPY_MODEL_a07567ea22ff49898ea6158065335362"
          }
        },
        "be73d346e0e741e183fc1da16217bcbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8ff4ccd1d964c198cfdb08909584122",
            "placeholder": "​",
            "style": "IPY_MODEL_0b11eadb0c9143b6bf76ab8188ded407",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "2d27ed6e50714a16a92aab8863826a85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_517afc68d1a34b4b928b0f7e84a0c268",
            "placeholder": "​",
            "style": "IPY_MODEL_5975d389a9944b638f3d9502f032e18c",
            "value": ""
          }
        },
        "3d81b0c0c62e488c903cb32a0f0a53a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_006966c354414f9bad622d6fd9df7c94",
            "style": "IPY_MODEL_23142ebfc80e4b7c9e219df77f5ea506",
            "value": true
          }
        },
        "5bb255281f44454fa5349c797070749f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_d6a0bd03dcbe4e4886899fe2d613058a",
            "style": "IPY_MODEL_41578712e3ab4a2e9c1b319038b61c72",
            "tooltip": ""
          }
        },
        "840aae9e28ad400f86a861b167add693": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08c002224cc34187abdfd2fdf5795ffd",
            "placeholder": "​",
            "style": "IPY_MODEL_3d95cf92b8eb466f9c5e8c7b78ca372a",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "a07567ea22ff49898ea6158065335362": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e8ff4ccd1d964c198cfdb08909584122": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b11eadb0c9143b6bf76ab8188ded407": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "517afc68d1a34b4b928b0f7e84a0c268": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5975d389a9944b638f3d9502f032e18c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "006966c354414f9bad622d6fd9df7c94": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23142ebfc80e4b7c9e219df77f5ea506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6a0bd03dcbe4e4886899fe2d613058a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41578712e3ab4a2e9c1b319038b61c72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "08c002224cc34187abdfd2fdf5795ffd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d95cf92b8eb466f9c5e8c7b78ca372a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c9dda9eeb42479e8bee0c43c44db98d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57866c43358f4faba132a6ac45dad8fe",
            "placeholder": "​",
            "style": "IPY_MODEL_01aa4c4eda3f4e6db213ab069d9f4bd6",
            "value": "Connecting..."
          }
        },
        "57866c43358f4faba132a6ac45dad8fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01aa4c4eda3f4e6db213ab069d9f4bd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nehasatheesh04/ASAG/blob/main/ASAG.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKBQlUk-pndy",
        "outputId": "3bb769d2-3410-4044-9001-b4c321f0cef1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 646 entries, 0 to 645\n",
            "Data columns (total 22 columns):\n",
            " #   Column               Non-Null Count  Dtype  \n",
            "---  ------               --------------  -----  \n",
            " 0   Unnamed: 0           646 non-null    int64  \n",
            " 1   question             646 non-null    object \n",
            " 2   student_answer       607 non-null    object \n",
            " 3   grades_round         646 non-null    int64  \n",
            " 4   student_modified     606 non-null    object \n",
            " 5   ref_answer           646 non-null    object \n",
            " 6   qn_modified          646 non-null    object \n",
            " 7   ref_modified         646 non-null    object \n",
            " 8   student_demoted      606 non-null    object \n",
            " 9   ref_demoted          646 non-null    object \n",
            " 10  length_ratio         646 non-null    float64\n",
            " 11  embed_ref            646 non-null    object \n",
            " 12  embed_stud           646 non-null    object \n",
            " 13  embed_ref_demoted    646 non-null    object \n",
            " 14  embed_stud_demoted   646 non-null    object \n",
            " 15  aligned              646 non-null    object \n",
            " 16  aligned_demoted      646 non-null    object \n",
            " 17  cos_similarity       646 non-null    float64\n",
            " 18  cos_similarity_demo  646 non-null    float64\n",
            " 19  aligned_score        646 non-null    float64\n",
            " 20  aligned_score_demo   646 non-null    float64\n",
            " 21  question_id          646 non-null    int64  \n",
            "dtypes: float64(5), int64(3), object(14)\n",
            "memory usage: 111.2+ KB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None,\n",
              "    Unnamed: 0                                           question  \\\n",
              " 0           0   Give a definition for the term \"artificial ne...   \n",
              " 1           1   Give a definition for the term \"artificial ne...   \n",
              " 2           2   Give a definition for the term \"artificial ne...   \n",
              " 3           3   Give a definition for the term \"artificial ne...   \n",
              " 4           4   Give a definition for the term \"artificial ne...   \n",
              " \n",
              "                                       student_answer  grades_round  \\\n",
              " 0  An artificial neural network is a massively pa...             2   \n",
              " 1  Artificial neural network consists of: . Large...             2   \n",
              " 2  An artificial neural network is a massive dist...             1   \n",
              " 3  An ANN is a layered graphical model containing...             2   \n",
              " 4  Artificial Neural Networks are large parallel ...             2   \n",
              " \n",
              "                                     student_modified  \\\n",
              " 0  artificial neural network massively parallel d...   \n",
              " 1  artificial neural network consists largely par...   \n",
              " 2  artificial neural network massive distributed ...   \n",
              " 3  ann layered graphical model containing neuron ...   \n",
              " 4  artificial neural network large parallel proce...   \n",
              " \n",
              "                                           ref_answer  \\\n",
              " 0  A neural network is a massively parallel distr...   \n",
              " 1  A neural network is a massively parallel distr...   \n",
              " 2  A neural network is a massively parallel distr...   \n",
              " 3  A neural network is a massively parallel distr...   \n",
              " 4  A neural network is a massively parallel distr...   \n",
              " \n",
              "                                          qn_modified  \\\n",
              " 0  give definition term artificial neural network...   \n",
              " 1  give definition term artificial neural network...   \n",
              " 2  give definition term artificial neural network...   \n",
              " 3  give definition term artificial neural network...   \n",
              " 4  give definition term artificial neural network...   \n",
              " \n",
              "                                         ref_modified  \\\n",
              " 0  neural network massively parallel distributed ...   \n",
              " 1  neural network massively parallel distributed ...   \n",
              " 2  neural network massively parallel distributed ...   \n",
              " 3  neural network massively parallel distributed ...   \n",
              " 4  neural network massively parallel distributed ...   \n",
              " \n",
              "                                      student_demoted  \\\n",
              " 0  massively parallel distributed processor simpl...   \n",
              " 1  consists largely parallel distributed processo...   \n",
              " 2  massive distributed processor consists several...   \n",
              " 3  ann layered graphical model containing neuron ...   \n",
              " 4  large parallel processing unit natural ability...   \n",
              " \n",
              "                                          ref_demoted  ...  \\\n",
              " 0  massively parallel distributed processor made ...  ...   \n",
              " 1  massively parallel distributed processor made ...  ...   \n",
              " 2  massively parallel distributed processor made ...  ...   \n",
              " 3  massively parallel distributed processor made ...  ...   \n",
              " 4  massively parallel distributed processor made ...  ...   \n",
              " \n",
              "                                           embed_stud  \\\n",
              " 0  [[ 2.2006836   0.86382484  0.27182007  2.55627...   \n",
              " 1  [[ 1.33543945  1.09904457  0.52998901  2.03334...   \n",
              " 2  [[ 0.41577148 -0.37836266  0.22351074  0.95300...   \n",
              " 3  [[ 2.1478271e+00  1.4641495e+00 -3.6404419e-01...   \n",
              " 4  [[ 8.80483398e-01  1.30450607e+00 -4.42072144e...   \n",
              " \n",
              "                                    embed_ref_demoted  \\\n",
              " 0  [[ 1.6300049e+00  1.5985355e+00 -1.2829590e-01...   \n",
              " 1  [[ 1.6300049e+00  1.5985355e+00 -1.2829590e-01...   \n",
              " 2  [[ 1.6300049e+00  1.5985355e+00 -1.2829590e-01...   \n",
              " 3  [[ 1.6300049e+00  1.5985355e+00 -1.2829590e-01...   \n",
              " 4  [[ 1.6300049e+00  1.5985355e+00 -1.2829590e-01...   \n",
              " \n",
              "                                   embed_stud_demoted  \\\n",
              " 0  [[ 2.0412598e+00  4.9321938e-01  1.0058594e-01...   \n",
              " 1  [[ 1.19566895  0.7539518   0.13561035  1.22295...   \n",
              " 2  [[ 3.84277344e-01 -4.89446640e-01  1.72241211e...   \n",
              " 3  [[ 1.97546387e+00  1.12967682e+00 -6.56402588e...   \n",
              " 4  [[ 0.68797852  0.72406174 -0.85735535  1.14616...   \n",
              " \n",
              "                                              aligned  \\\n",
              " 0  [['neural', 'neural'], ['network', 'network'],...   \n",
              " 1  [['knowledge', 'knowledge'], ['parallel', 'par...   \n",
              " 2  [['knowledge', 'knowledge'], ['neural', 'neura...   \n",
              " 3  [['resemble', 'resembling'], ['neural', 'neuro...   \n",
              " 4  [['knowledge', 'knowledge'], ['processing', 'p...   \n",
              " \n",
              "                                      aligned_demoted cos_similarity  \\\n",
              " 0  [['simple', 'simple'], ['processing', 'process...       0.947867   \n",
              " 1  [['knowledge', 'knowledge'], ['knowledge', 'kn...       0.964398   \n",
              " 2  [['knowledge', 'knowledge'], ['distributed', '...       0.854767   \n",
              " 3  [['environment', 'environment'], ['learning', ...       0.788166   \n",
              " 4  [['knowledge', 'knowledge'], ['processing', 'p...       0.894408   \n",
              " \n",
              "   cos_similarity_demo  aligned_score  aligned_score_demo  question_id  \n",
              " 0            0.933466       0.969697            0.950888            1  \n",
              " 1            0.951182       0.883259            0.818713            1  \n",
              " 2            0.775333       0.498039            0.465632            1  \n",
              " 3            0.735229       0.322950            0.220386            1  \n",
              " 4            0.828665       0.585639            0.482094            1  \n",
              " \n",
              " [5 rows x 22 columns])"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = \"/content/drive/MyDrive/asag_dataset.csv\"\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Display basic information about the dataset\n",
        "df.info(), df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "\n",
        "\n",
        "# Ensure required columns exist\n",
        "required_columns = {'ref_answer', 'student_answer', 'grades_round'}\n",
        "if not required_columns.issubset(df.columns):\n",
        "    raise KeyError(f\"Missing columns: {required_columns - set(df.columns)}\")\n",
        "\n",
        "# Extract necessary columns\n",
        "ref_answers = df['ref_answer'].astype(str).values  # Convert to string to avoid errors\n",
        "stud_answers = df['student_answer'].astype(str).values\n",
        "grades = df['grades_round'].astype(float).values  # Convert grades to float\n",
        "\n",
        "# Initialize TF-IDF vectorizer\n",
        "vectorizer = TfidfVectorizer()\n",
        "\n",
        "# Fit and transform reference answers\n",
        "ref_tfidf = vectorizer.fit_transform(ref_answers)\n",
        "\n",
        "# Transform student answers\n",
        "stud_tfidf = vectorizer.transform(stud_answers)\n",
        "\n",
        "# Compute cosine similarity for each answer pair\n",
        "cos_sim = cosine_similarity(ref_tfidf, stud_tfidf).diagonal().reshape(-1, 1)\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(cos_sim, grades, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "accuracy = (1 - (mae / np.mean(y_test))) * 100\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7C_OkPmquBM",
        "outputId": "75e04635-2256-4b5e-d01d-2f5becaba8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.529\n",
            "R² Score: 0.209\n",
            "Accuracy: 61.77%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM\n"
      ],
      "metadata": {
        "id": "lGZTgFfGvcfP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, GlobalAveragePooling1D\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/asag_dataset.csv\")  # Update filename if necessary\n",
        "\n",
        "# Ensure required columns exist\n",
        "required_columns = {'ref_answer', 'student_answer', 'grades_round'}\n",
        "if not required_columns.issubset(df.columns):\n",
        "    raise KeyError(f\"Missing columns: {required_columns - set(df.columns)}\")\n",
        "\n",
        "# Extract necessary columns\n",
        "ref_answers = df['ref_answer'].astype(str).values  # Convert to string to avoid errors\n",
        "stud_answers = df['student_answer'].astype(str).values\n",
        "grades = df['grades_round'].astype(float).values  # Convert grades to float\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(np.concatenate((ref_answers, stud_answers), axis=0))\n",
        "\n",
        "# Convert text to sequences\n",
        "ref_sequences = tokenizer.texts_to_sequences(ref_answers)\n",
        "stud_sequences = tokenizer.texts_to_sequences(stud_answers)\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max(max(len(seq) for seq in ref_sequences), max(len(seq) for seq in stud_sequences))\n",
        "ref_padded = pad_sequences(ref_sequences, maxlen=max_length, padding='post')\n",
        "stud_padded = pad_sequences(stud_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Compute absolute difference between encoded sequences\n",
        "diff_padded = np.abs(ref_padded - stud_padded)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(diff_padded, grades, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define LSTM Model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 50\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=max_length),\n",
        "    LSTM(64, return_sequences=True),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Regression output\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, epochs=10, batch_size=16, validation_data=(X_test, y_test))\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "accuracy = (1 - (mae / np.mean(y_test))) * 100  # Compute accuracy as a percentage\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JzPKTgnvt_Zy",
        "outputId": "9ea47226-fb46-42b7-d8fd-deaf473bfda9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 115ms/step - loss: 1.2643 - mae: 0.9356 - val_loss: 0.5142 - val_mae: 0.6433\n",
            "Epoch 2/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 138ms/step - loss: 0.5806 - mae: 0.6713 - val_loss: 0.4575 - val_mae: 0.6120\n",
            "Epoch 3/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 101ms/step - loss: 0.5173 - mae: 0.6421 - val_loss: 0.4317 - val_mae: 0.5891\n",
            "Epoch 4/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.4401 - mae: 0.5863 - val_loss: 0.4038 - val_mae: 0.5667\n",
            "Epoch 5/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 138ms/step - loss: 0.3583 - mae: 0.5179 - val_loss: 0.5071 - val_mae: 0.5574\n",
            "Epoch 6/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - loss: 0.3000 - mae: 0.4279 - val_loss: 0.4104 - val_mae: 0.5351\n",
            "Epoch 7/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.2215 - mae: 0.4008 - val_loss: 0.3523 - val_mae: 0.5025\n",
            "Epoch 8/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 98ms/step - loss: 0.2160 - mae: 0.3712 - val_loss: 0.3479 - val_mae: 0.4868\n",
            "Epoch 9/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 157ms/step - loss: 0.1802 - mae: 0.3320 - val_loss: 0.3708 - val_mae: 0.5066\n",
            "Epoch 10/10\n",
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 102ms/step - loss: 0.1363 - mae: 0.2888 - val_loss: 0.3972 - val_mae: 0.4997\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 116ms/step\n",
            "Mean Absolute Error (MAE): 0.500\n",
            "R² Score: 0.121\n",
            "Accuracy: 63.91%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-827zCsriMPX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "improved lstm......word embedding like glove\n"
      ],
      "metadata": {
        "id": "K1AffYqyvfAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "!unzip glove.6B.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpoDldtLx_43",
        "outputId": "d137289c-82b5-43ac-b789-4af9e3c8d55b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-03-30 20:39:38--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2025-03-30 20:39:39--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2025-03-30 20:39:39--  https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  4.97MB/s    in 2m 41s  \n",
            "\n",
            "2025-03-30 20:42:20 (5.12 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, GlobalAveragePooling1D, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/asag_dataset.csv\")  # Update filename if necessary\n",
        "\n",
        "# Ensure required columns exist\n",
        "required_columns = {'ref_answer', 'student_answer', 'grades_round'}\n",
        "if not required_columns.issubset(df.columns):\n",
        "    raise KeyError(f\"Missing columns: {required_columns - set(df.columns)}\")\n",
        "\n",
        "# Extract necessary columns\n",
        "ref_answers = df['ref_answer'].astype(str).values  # Convert to string to avoid errors\n",
        "stud_answers = df['student_answer'].astype(str).values\n",
        "grades = df['grades_round'].astype(float).values  # Convert grades to float\n",
        "\n",
        "# Tokenization\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(np.concatenate((ref_answers, stud_answers), axis=0))\n",
        "\n",
        "# Convert text to sequences\n",
        "ref_sequences = tokenizer.texts_to_sequences(ref_answers)\n",
        "stud_sequences = tokenizer.texts_to_sequences(stud_answers)\n",
        "\n",
        "# Padding sequences\n",
        "max_length = max(max(len(seq) for seq in ref_sequences), max(len(seq) for seq in stud_sequences))\n",
        "ref_padded = pad_sequences(ref_sequences, maxlen=max_length, padding='post')\n",
        "stud_padded = pad_sequences(stud_sequences, maxlen=max_length, padding='post')\n",
        "\n",
        "# Compute absolute difference between encoded sequences\n",
        "diff_padded = np.abs(ref_padded - stud_padded)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(diff_padded, grades, test_size=0.2, random_state=42)\n",
        "\n",
        "# Load GloVe word embeddings\n",
        "def load_glove_embeddings(filepath, tokenizer, embedding_dim):\n",
        "    embeddings_index = {}\n",
        "    with open(filepath, encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            values = line.split()\n",
        "            word = values[0]\n",
        "            coefs = np.asarray(values[1:], dtype='float32')\n",
        "            embeddings_index[word] = coefs\n",
        "\n",
        "    vocab_size = len(tokenizer.word_index) + 1\n",
        "    embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "    for word, i in tokenizer.word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "    return embedding_matrix\n",
        "\n",
        "embedding_dim = 100  # Use GloVe 100D\n",
        "embedding_matrix = load_glove_embeddings(\"glove.6B.100d.txt\", tokenizer, embedding_dim)\n",
        "\n",
        "# Define Improved LSTM Model\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "model = Sequential([\n",
        "    Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], input_length=max_length, trainable=False),\n",
        "    Bidirectional(LSTM(128, return_sequences=True)),\n",
        "    GlobalAveragePooling1D(),\n",
        "    Dense(128, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Regression output\n",
        "])\n",
        "\n",
        "# Compile Model\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
        "\n",
        "# Train Model\n",
        "model.fit(X_train, y_train, epochs=15, batch_size=32, validation_data=(X_test, y_test))\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "accuracy = (1 - (mae / np.mean(y_test))) * 100  # Compute accuracy as a percentage\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asxVioaRvuLK",
        "outputId": "9479101a-cac3-4c79-d3e6-06a441b23ffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 780ms/step - loss: 1.0668 - mae: 0.8551 - val_loss: 0.5060 - val_mae: 0.5918\n",
            "Epoch 2/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 832ms/step - loss: 0.5681 - mae: 0.6020 - val_loss: 0.4937 - val_mae: 0.5815\n",
            "Epoch 3/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 786ms/step - loss: 0.4979 - mae: 0.5790 - val_loss: 0.4075 - val_mae: 0.5377\n",
            "Epoch 4/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 532ms/step - loss: 0.5269 - mae: 0.6086 - val_loss: 0.3998 - val_mae: 0.5314\n",
            "Epoch 5/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 788ms/step - loss: 0.4920 - mae: 0.5909 - val_loss: 0.3841 - val_mae: 0.5212\n",
            "Epoch 6/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 756ms/step - loss: 0.4686 - mae: 0.5863 - val_loss: 0.3792 - val_mae: 0.5130\n",
            "Epoch 7/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 777ms/step - loss: 0.4007 - mae: 0.5347 - val_loss: 0.3288 - val_mae: 0.4744\n",
            "Epoch 8/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 808ms/step - loss: 0.3782 - mae: 0.5122 - val_loss: 0.3164 - val_mae: 0.4638\n",
            "Epoch 9/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 748ms/step - loss: 0.4057 - mae: 0.5196 - val_loss: 0.3233 - val_mae: 0.4710\n",
            "Epoch 10/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 582ms/step - loss: 0.3730 - mae: 0.5114 - val_loss: 0.3032 - val_mae: 0.4538\n",
            "Epoch 11/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 785ms/step - loss: 0.3381 - mae: 0.4818 - val_loss: 0.3465 - val_mae: 0.4910\n",
            "Epoch 12/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 586ms/step - loss: 0.3641 - mae: 0.5009 - val_loss: 0.2967 - val_mae: 0.4435\n",
            "Epoch 13/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 793ms/step - loss: 0.3396 - mae: 0.4730 - val_loss: 0.3525 - val_mae: 0.4930\n",
            "Epoch 14/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 577ms/step - loss: 0.3528 - mae: 0.4820 - val_loss: 0.3240 - val_mae: 0.4665\n",
            "Epoch 15/15\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 767ms/step - loss: 0.3309 - mae: 0.4748 - val_loss: 0.3448 - val_mae: 0.4898\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 244ms/step\n",
            "Mean Absolute Error (MAE): 0.490\n",
            "R² Score: 0.237\n",
            "Accuracy: 64.62%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Pretrained BERT-Based ASAG"
      ],
      "metadata": {
        "id": "EQMPw0JT2G6y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17,
          "referenced_widgets": [
            "65216fa69c07431c890eb2f34ceff79b",
            "be73d346e0e741e183fc1da16217bcbd",
            "2d27ed6e50714a16a92aab8863826a85",
            "3d81b0c0c62e488c903cb32a0f0a53a3",
            "5bb255281f44454fa5349c797070749f",
            "840aae9e28ad400f86a861b167add693",
            "a07567ea22ff49898ea6158065335362",
            "e8ff4ccd1d964c198cfdb08909584122",
            "0b11eadb0c9143b6bf76ab8188ded407",
            "517afc68d1a34b4b928b0f7e84a0c268",
            "5975d389a9944b638f3d9502f032e18c",
            "006966c354414f9bad622d6fd9df7c94",
            "23142ebfc80e4b7c9e219df77f5ea506",
            "d6a0bd03dcbe4e4886899fe2d613058a",
            "41578712e3ab4a2e9c1b319038b61c72",
            "08c002224cc34187abdfd2fdf5795ffd",
            "3d95cf92b8eb466f9c5e8c7b78ca372a",
            "9c9dda9eeb42479e8bee0c43c44db98d",
            "57866c43358f4faba132a6ac45dad8fe",
            "01aa4c4eda3f4e6db213ab069d9f4bd6"
          ]
        },
        "id": "tE1PG0035YSP",
        "outputId": "462d2a61-f781-4b69-e2fd-b0ab7b98acd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "65216fa69c07431c890eb2f34ceff79b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli whoami\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XO4CZLzy5r1K",
        "outputId": "dc65e0db-0733-4ac7-b6ed-c50d46ff80f5",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimplyNeha\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/asag_dataset.csv\")  # Ensure correct filename\n",
        "\n",
        "# Ensure required columns exist\n",
        "required_columns = {'ref_answer', 'student_answer', 'grades_round'}\n",
        "if not required_columns.issubset(df.columns):\n",
        "    raise KeyError(f\"Missing columns: {required_columns - set(df.columns)}\")\n",
        "\n",
        "# Extract necessary columns\n",
        "ref_answers = df['ref_answer'].astype(str).tolist()\n",
        "stud_answers = df['student_answer'].astype(str).tolist()\n",
        "grades = df['grades_round'].astype(float).values  # Convert grades to float\n",
        "\n",
        "# Load Pretrained BERT\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Function to extract BERT embeddings\n",
        "def get_bert_embeddings(text_list):\n",
        "    embeddings = []\n",
        "    for text in text_list:\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "        cls_embedding = outputs.last_hidden_state[:, 0, :].squeeze().numpy()  # Use [CLS] token embedding\n",
        "        embeddings.append(cls_embedding)\n",
        "    return np.array(embeddings)\n",
        "\n",
        "# Extract BERT embeddings\n",
        "ref_embeddings = get_bert_embeddings(ref_answers)\n",
        "stud_embeddings = get_bert_embeddings(stud_answers)\n",
        "\n",
        "# Compute absolute difference between embeddings (distance measure)\n",
        "X = np.abs(ref_embeddings - stud_embeddings)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, grades, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Linear Regression Model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate\n",
        "y_pred = model.predict(X_test)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "accuracy = (1 - (mae / np.mean(y_test))) * 100  # Compute accuracy\n",
        "\n",
        "# Display Results\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ac1tb4ob0eJw",
        "outputId": "621bd5a9-555e-4783-b7a5-8900d47615ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.696\n",
            "R² Score: -0.756\n",
            "Accuracy: 49.70%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Fine-Tune BERT for ASAG"
      ],
      "metadata": {
        "id": "Z97tvGIl8xOt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertTokenizer, BertModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/asag_dataset.csv\")\n",
        "\n",
        "# Tokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# Tokenization function\n",
        "def tokenize_data(ref_texts, stud_texts, tokenizer, max_len=256):\n",
        "    return tokenizer(\n",
        "        list(ref_texts), list(stud_texts),\n",
        "        padding='max_length', truncation=\"only_second\",\n",
        "        max_length=max_len, return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "# Tokenize both reference and student answers\n",
        "tokenized_data = tokenize_data(df['ref_answer'].astype(str), df['student_answer'].astype(str), tokenizer)\n",
        "\n",
        "input_ids = tokenized_data['input_ids']\n",
        "attention_mask = tokenized_data['attention_mask']\n",
        "\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create DataLoader\n",
        "train_dataset = TensorDataset(X_train, y_train)\n",
        "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test, y_test)\n",
        "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
        "\n",
        "# Define Fine-tuned BERT Model\n",
        "class BertRegressionModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(BertRegressionModel, self).__init__()\n",
        "        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "        self.regressor = nn.Linear(self.bert.config.hidden_size, 1)  # Regression output\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        pooled_output = outputs.pooler_output\n",
        "        return self.regressor(pooled_output)\n",
        "\n",
        "# Initialize Model\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = BertRegressionModel().to(device)\n",
        "\n",
        "# Loss and Optimizer\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=2e-5)\n",
        "\n",
        "# Training Loop\n",
        "def train_model(model, train_loader, criterion, optimizer, epochs=15):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        for batch in train_loader:\n",
        "            input_ids, labels = batch\n",
        "            input_ids = input_ids.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(input_ids=input_ids, attention_mask=(input_ids > 0).long()).squeeze()\n",
        "            loss = criterion(predictions, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss / len(train_loader)}\")\n",
        "\n",
        "train_model(model, train_loader, criterion, optimizer, epochs=15)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5OuAjnu8zDk",
        "outputId": "bcdc2eb2-f78e-4069-ed0f-7ea6d85b5529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1, Loss: 0.5464955893429843\n",
            "Epoch 2, Loss: 0.30822799806341983\n",
            "Epoch 3, Loss: 0.24821928775671756\n",
            "Epoch 4, Loss: 0.20133014486143083\n",
            "Epoch 5, Loss: 0.15017854715838577\n",
            "Epoch 6, Loss: 0.1053885475478389\n",
            "Epoch 7, Loss: 0.06486132295068467\n",
            "Epoch 8, Loss: 0.041677157930804024\n",
            "Epoch 9, Loss: 0.03009343816136772\n",
            "Epoch 10, Loss: 0.027963122578732895\n",
            "Epoch 11, Loss: 0.027171308400504517\n",
            "Epoch 12, Loss: 0.024267390539700336\n",
            "Epoch 13, Loss: 0.014683837889496124\n",
            "Epoch 14, Loss: 0.012527317697690292\n",
            "Epoch 15, Loss: 0.011810952599978808\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    predictions, actuals = [], []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in test_loader:\n",
        "            input_ids, labels = batch\n",
        "            input_ids = input_ids.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            preds = model(input_ids=input_ids, attention_mask=(input_ids > 0).long()).squeeze()\n",
        "            predictions.extend(preds.cpu().numpy())\n",
        "            actuals.extend(labels.cpu().numpy())\n",
        "\n",
        "    return predictions, actuals\n",
        "\n",
        "y_pred, y_true = evaluate(model, test_loader)\n",
        "\n",
        "# Compute MAE and R² Score\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2 = r2_score(y_true, y_pred)\n",
        "accuracy = (1 - (mae / np.mean(y_true))) * 100  # Accuracy formula\n",
        "\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.3f}\")\n",
        "print(f\"R² Score: {r2:.3f}\")\n",
        "print(f\"Accuracy: {accuracy:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uK2dJsGWNVdU",
        "outputId": "1140fa0f-1beb-4470-82a4-4165978e6525"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.351\n",
            "R² Score: 0.395\n",
            "Accuracy: 74.66%\n"
          ]
        }
      ]
    }
  ]
}